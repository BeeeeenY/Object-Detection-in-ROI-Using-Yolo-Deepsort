{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d6f4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# comment out below line to enable tensorflow logging outputs\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a18122f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'easydict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-1cbfe75e5f92>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mabsl\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mabsl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myolov4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfilter_boxes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaved_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtag_constants\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Downloads\\Monitoring-system\\Vehicle_Detection_main-yolov4deepsort\\core\\utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcfg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolor_recognition_module\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcolor_recognition_api\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Downloads\\Monitoring-system\\Vehicle_Detection_main-yolov4deepsort\\core\\config.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#! /usr/bin/env python\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# coding=utf-8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0measydict\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEasyDict\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0medict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'easydict'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "from absl import app, flags, logging\n",
    "from absl.flags import FLAGS\n",
    "import core.utils as utils\n",
    "from core.yolov4 import filter_boxes\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "from core.config import cfg\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "# deep sort imports\n",
    "from deep_sort import preprocessing, nn_matching\n",
    "from deep_sort.detection import Detection\n",
    "from deep_sort.tracker import Tracker\n",
    "from tools import generate_detections as gdet\n",
    "flags.DEFINE_string('framework', 'tf', '(tf, tflite, trt')\n",
    "flags.DEFINE_string('weights', './checkpoints/yolov4-416',\n",
    "                    'path to weights file')\n",
    "flags.DEFINE_integer('size', 416, 'resize images to')\n",
    "flags.DEFINE_boolean('tiny', False, 'yolo or yolo-tiny')\n",
    "flags.DEFINE_string('model', 'yolov4', 'yolov3 or yolov4')\n",
    "flags.DEFINE_string('video', './data/video/test.mp4', 'path to input video or set to 0 for webcam')\n",
    "flags.DEFINE_string('output', None, 'path to output video')\n",
    "flags.DEFINE_string('output_format', 'XVID', 'codec used in VideoWriter when saving video to file')\n",
    "flags.DEFINE_float('iou', 0.45, 'iou threshold')\n",
    "flags.DEFINE_float('score', 0.50, 'score threshold')\n",
    "flags.DEFINE_boolean('dont_show', False, 'dont show video output')\n",
    "flags.DEFINE_boolean('info', False, 'show detailed info of tracked objects')\n",
    "flags.DEFINE_boolean('count', False, 'count objects being tracked on screen')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19cf7fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(_argv):\n",
    "   \n",
    "    max_cosine_distance = 0.4\n",
    "    nn_budget = None\n",
    "    nms_max_overlap = 1.0\n",
    "    \n",
    "  \n",
    "    model_filename = 'model_data/mars-small128.pb'\n",
    "    encoder = gdet.create_box_encoder(model_filename, batch_size=1)\n",
    "   \n",
    "    metric = nn_matching.NearestNeighborDistanceMetric(\"cosine\", max_cosine_distance, nn_budget)\n",
    "    \n",
    "    tracker = Tracker(metric)\n",
    "\n",
    "   \n",
    "    config = ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    session = InteractiveSession(config=config)\n",
    "    STRIDES, ANCHORS, NUM_CLASS, XYSCALE = utils.load_config(FLAGS)\n",
    "    input_size = FLAGS.size\n",
    "    video_path = FLAGS.video\n",
    "\n",
    "   \n",
    "    if FLAGS.framework == 'tflite':\n",
    "        interpreter = tf.lite.Interpreter(model_path=FLAGS.weights)\n",
    "        interpreter.allocate_tensors()\n",
    "        input_details = interpreter.get_input_details()\n",
    "        output_details = interpreter.get_output_details()\n",
    "        print(input_details)\n",
    "        print(output_details)\n",
    "    \n",
    "    else:\n",
    "        saved_model_loaded = tf.saved_model.load(FLAGS.weights, tags=[tag_constants.SERVING])\n",
    "        infer = saved_model_loaded.signatures['serving_default']\n",
    "\n",
    "   \n",
    "    try:\n",
    "        vid = cv2.VideoCapture(int(video_path))\n",
    "    except:\n",
    "        vid = cv2.VideoCapture(video_path)\n",
    "\n",
    "    out = None\n",
    "\n",
    "    \n",
    "    if FLAGS.output:\n",
    "        width = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        fps = int(vid.get(cv2.CAP_PROP_FPS))\n",
    "        codec = cv2.VideoWriter_fourcc(*FLAGS.output_format)\n",
    "        out = cv2.VideoWriter(FLAGS.output, codec, fps, (width, height))\n",
    "\n",
    "    frame_num = 0\n",
    "   \n",
    "    while True:\n",
    "        return_value, frame = vid.read()\n",
    "        if return_value:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image = Image.fromarray(frame)\n",
    "        else:\n",
    "            print('Video has ended or failed, try a different video format!')\n",
    "            break\n",
    "        frame_num +=1\n",
    "        print('Frame #: ', frame_num)\n",
    "        frame_size = frame.shape[:2]\n",
    "        image_data = cv2.resize(frame, (input_size, input_size))\n",
    "        image_data = image_data / 255.\n",
    "        image_data = image_data[np.newaxis, ...].astype(np.float32)\n",
    "        start_time = time.time()\n",
    "\n",
    "        if FLAGS.framework == 'tflite':\n",
    "            interpreter.set_tensor(input_details[0]['index'], image_data)\n",
    "            interpreter.invoke()\n",
    "            pred = [interpreter.get_tensor(output_details[i]['index']) for i in range(len(output_details))]\n",
    "\n",
    "            if FLAGS.model == 'yolov3' and FLAGS.tiny == True:\n",
    "                boxes, pred_conf = filter_boxes(pred[1], pred[0], score_threshold=0.25,\n",
    "                                                input_shape=tf.constant([input_size, input_size]))\n",
    "            else:\n",
    "                boxes, pred_conf = filter_boxes(pred[0], pred[1], score_threshold=0.25,\n",
    "                                                input_shape=tf.constant([input_size, input_size]))\n",
    "        else:\n",
    "            batch_data = tf.constant(image_data)\n",
    "            pred_bbox = infer(batch_data)\n",
    "            for key, value in pred_bbox.items():\n",
    "                boxes = value[:, :, 0:4]\n",
    "                pred_conf = value[:, :, 4:]\n",
    "\n",
    "        boxes, scores, classes, valid_detections = tf.image.combined_non_max_suppression(\n",
    "            boxes=tf.reshape(boxes, (tf.shape(boxes)[0], -1, 1, 4)),\n",
    "            scores=tf.reshape(\n",
    "                pred_conf, (tf.shape(pred_conf)[0], -1, tf.shape(pred_conf)[-1])),\n",
    "            max_output_size_per_class=50,\n",
    "            max_total_size=50,\n",
    "            iou_threshold=FLAGS.iou,\n",
    "            score_threshold=FLAGS.score\n",
    "        )\n",
    "\n",
    "        num_objects = valid_detections.numpy()[0]\n",
    "        bboxes = boxes.numpy()[0]\n",
    "        bboxes = bboxes[0:int(num_objects)]\n",
    "        scores = scores.numpy()[0]\n",
    "        scores = scores[0:int(num_objects)]\n",
    "        classes = classes.numpy()[0]\n",
    "        classes = classes[0:int(num_objects)]\n",
    "\n",
    "        original_h, original_w, _ = frame.shape\n",
    "        bboxes = utils.format_boxes(bboxes, original_h, original_w)\n",
    "\n",
    "        pred_bbox = [bboxes, scores, classes, num_objects]\n",
    "\n",
    "        class_names = utils.read_class_names(cfg.YOLO.CLASSES)\n",
    "\n",
    "        allowed_classes = list(class_names.values())\n",
    "        \n",
    "    \n",
    "        names = []\n",
    "        deleted_indx = []\n",
    "        for i in range(num_objects):\n",
    "            class_indx = int(classes[i])\n",
    "            class_name = class_names[class_indx]\n",
    "            if class_name not in allowed_classes:\n",
    "                deleted_indx.append(i)\n",
    "            else:\n",
    "                names.append(class_name)\n",
    "        names = np.array(names)\n",
    "        count = len(names)\n",
    "        if FLAGS.count:\n",
    "            cv2.putText(frame, \"Objects being tracked: {}\".format(count), (5, 35), cv2.FONT_HERSHEY_COMPLEX_SMALL, 2, (0, 255, 0), 2)\n",
    "            print(\"Objects being tracked: {}\".format(count))\n",
    "        \n",
    "        bboxes = np.delete(bboxes, deleted_indx, axis=0)\n",
    "        scores = np.delete(scores, deleted_indx, axis=0)\n",
    "\n",
    "        features = encoder(frame, bboxes)\n",
    "        detections = [Detection(bbox, score, class_name, feature) for bbox, score, class_name, feature in zip(bboxes, scores, names, features)]\n",
    "\n",
    "        cmap = plt.get_cmap('tab20b')\n",
    "        colors = [cmap(i)[:3] for i in np.linspace(0, 1, 20)]\n",
    "\n",
    "        boxs = np.array([d.tlwh for d in detections])\n",
    "        scores = np.array([d.confidence for d in detections])\n",
    "        classes = np.array([d.class_name for d in detections])\n",
    "        indices = preprocessing.non_max_suppression(boxs, classes, nms_max_overlap, scores)\n",
    "        detections = [detections[i] for i in indices]       \n",
    "\n",
    "        tracker.predict()\n",
    "        tracker.update(detections)\n",
    "\n",
    "        for track in tracker.tracks:\n",
    "            if not track.is_confirmed() or track.time_since_update > 1:\n",
    "                continue \n",
    "            bbox = track.to_tlbr()\n",
    "            class_name = track.get_class()\n",
    "            \n",
    "            color = colors[int(track.track_id) % len(colors)]\n",
    "            color = [i * 255 for i in color]\n",
    "            cv2.rectangle(frame, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), color, 2)\n",
    "            cv2.rectangle(frame, (int(bbox[0]), int(bbox[1]-30)), (int(bbox[0])+(len(class_name)+len(str(track.track_id)))*17, int(bbox[1])), color, -1)\n",
    "            cv2.putText(frame, class_name + \"-\" + str(track.track_id),(int(bbox[0]), int(bbox[1]-10)),0, 0.75, (255,255,255),2)\n",
    "\n",
    "            if FLAGS.info:\n",
    "                print(\"Tracker ID: {}, Class: {},  BBox Coords (xmin, ymin, xmax, ymax): {}\".format(str(track.track_id), class_name, (int(bbox[0]), int(bbox[1]), int(bbox[2]), int(bbox[3]))))\n",
    "\n",
    "       \n",
    "        fps = 1.0 / (time.time() - start_time)\n",
    "        print(\"FPS: %.2f\" % fps)\n",
    "        result = np.asarray(frame)\n",
    "        result = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        if not FLAGS.dont_show:\n",
    "            cv2.imshow(\"Output Video\", result)\n",
    "        \n",
    "        \n",
    "        if FLAGS.output:\n",
    "            out.write(result)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'): break\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f6ca0fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'app' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-243392e41e8e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'app' is not defined"
     ]
    }
   ],
   "source": [
    "app.run(main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3339bb9a",
   "metadata": {},
   "outputs": [
    {
     "ename": "DuplicateFlagError",
     "evalue": "The flag 'framework' is defined twice. First from D:\\software\\Anaconda\\envs\\yolov4-gpu\\lib\\site-packages\\ipykernel_launcher.py, Second from object_tracker.py.  Description from first occurrence: (tf, tflite, trt",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDuplicateFlagError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\Downloads\\intern\\supervised learning approach\\yolo+deepsort\\yolov4-deepsort-master\\object_tracker.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdeep_sort\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtracker\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTracker\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgenerate_detections\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgdet\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDEFINE_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'framework'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'tf'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'(tf, tflite, trt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m flags.DEFINE_string('weights', './checkpoints/yolov4-416',\n\u001b[0;32m     28\u001b[0m                     'path to weights file')\n",
      "\u001b[1;32mD:\\software\\Anaconda\\envs\\yolov4-gpu\\lib\\site-packages\\absl\\flags\\_defines.py\u001b[0m in \u001b[0;36mDEFINE_string\u001b[1;34m(name, default, help, flag_values, required, **args)\u001b[0m\n\u001b[0;32m    292\u001b[0m       \u001b[0mserializer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m       \u001b[0mrequired\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequired\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 294\u001b[1;33m       **args)\n\u001b[0m\u001b[0;32m    295\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\Anaconda\\envs\\yolov4-gpu\\lib\\site-packages\\absl\\flags\\_defines.py\u001b[0m in \u001b[0;36mDEFINE\u001b[1;34m(parser, name, default, help, flag_values, serializer, module_name, required, **args)\u001b[0m\n\u001b[0;32m    104\u001b[0m   return DEFINE_flag(\n\u001b[0;32m    105\u001b[0m       \u001b[0m_flag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFlag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mserializer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhelp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflag_values\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m       module_name, required)\n\u001b[0m\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\Anaconda\\envs\\yolov4-gpu\\lib\\site-packages\\absl\\flags\\_defines.py\u001b[0m in \u001b[0;36mDEFINE_flag\u001b[1;34m(flag, flag_values, module_name, required)\u001b[0m\n\u001b[0;32m    138\u001b[0m   \u001b[1;31m# Copying the reference to flag_values prevents pychecker warnings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m   \u001b[0mfv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mflag_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m   \u001b[0mfv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mflag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m   \u001b[1;31m# Tell flag_values who's defining the flag.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\Anaconda\\envs\\yolov4-gpu\\lib\\site-packages\\absl\\flags\\_flagvalues.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, name, flag)\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;31m# module is simply being imported a subsequent time.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0m_exceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDuplicateFlagError\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_flag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    440\u001b[0m     \u001b[0mshort_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshort_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m     \u001b[1;31m# If a new flag overrides an old one, we need to cleanup the old flag's\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDuplicateFlagError\u001b[0m: The flag 'framework' is defined twice. First from D:\\software\\Anaconda\\envs\\yolov4-gpu\\lib\\site-packages\\ipykernel_launcher.py, Second from object_tracker.py.  Description from first occurrence: (tf, tflite, trt"
     ]
    }
   ],
   "source": [
    "run object_tracker.py --video ./data/video/test.mp4 --output ./outputs/demo.avi --model yolov4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9a759ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FATAL Flags parsing error: Unknown command line flag 'f'\n",
      "Pass --helpshort or --helpfull to see help on flags.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        app.run(main)\n",
    "    except SystemExit:\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
